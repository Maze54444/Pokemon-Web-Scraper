import requests
import re
from bs4 import BeautifulSoup
from utils.telegram import send_telegram_message
from utils.matcher import is_keyword_in_text, clean_text

def scrape_tcgviert(keywords_map, seen):
    """
    Scraper f√ºr tcgviert.com
    
    :param keywords_map: Dictionary mit Suchbegriffen und ihren Tokens
    :param seen: Set mit bereits gesehenen Produkttiteln
    :return: Liste der neuen Treffer
    """
    print("üåê Starte Scraper f√ºr tcgviert.com", flush=True)
    print(f"üîç Suche nach folgenden Begriffen: {list(keywords_map.keys())}", flush=True)
    
    json_matches = []
    html_matches = []
    
    # Versuche beide Methoden und kombiniere die Ergebnisse
    try:
        json_matches = scrape_tcgviert_json(keywords_map, seen)
    except Exception as e:
        print(f"‚ùå Fehler beim JSON-Scraping: {e}", flush=True)
    
    try:
        # Hauptseite scrapen, um die richtigen Collection-URLs zu finden
        main_page_urls = discover_collection_urls()
        if main_page_urls:
            html_matches = scrape_tcgviert_html(main_page_urls, keywords_map, seen)
    except Exception as e:
        print(f"‚ùå Fehler beim HTML-Scraping: {e}", flush=True)
    
    # Kombiniere eindeutige Ergebnisse
    all_matches = list(set(json_matches + html_matches))
    print(f"‚úÖ Insgesamt {len(all_matches)} einzigartige Treffer gefunden", flush=True)
    return all_matches

def extract_product_info(title):
    """
    Extrahiert wichtige Produktinformationen aus dem Titel f√ºr eine pr√§zise ID-Erstellung
    
    :param title: Produkttitel
    :return: Tupel mit (series_code, product_type, language)
    """
    # Extrahiere Sprache (DE/EN/JP)
    if "(DE)" in title or "pro Person" in title:
        language = "DE"
    elif "(EN)" in title or "per person" in title:
        language = "EN"
    elif "(JP)" in title or "japan" in title.lower():
        language = "JP"
    else:
        language = "UNK"
    
    # Extrahiere Produkttyp
    product_type = "unknown"
    if re.search(r'display|36er', title.lower()):
        product_type = "display"
    elif re.search(r'booster|pack|sleeve', title.lower()):
        product_type = "booster"
    elif re.search(r'trainer box|elite trainer|box|tin', title.lower()):
        product_type = "box"
    elif re.search(r'blister|check\s?lane', title.lower()):
        product_type = "blister"
    
    # Extrahiere Serien-/Set-Code
    series_code = "unknown"
    # Suche nach Standard-Codes wie SV09, KP09, etc.
    code_match = re.search(r'(?:sv|kp|op)(?:\s|-)?\d+', title.lower())
    if code_match:
        series_code = code_match.group(0).replace(" ", "").replace("-", "")
    # Spezifische Serien-Namen
    elif "journey together" in title.lower():
        series_code = "sv09"
    elif "reisegef√§hrten" in title.lower():
        series_code = "kp09"
    elif "royal blood" in title.lower():
        series_code = "op10"
    
    return (series_code, product_type, language)

def create_product_id(title, base_id="tcgviert"):
    """
    Erstellt eine eindeutige Produkt-ID basierend auf Titel und Produktinformationen
    
    :param title: Produkttitel
    :param base_id: Basis-ID (z.B. Website-Name)
    :return: Eindeutige Produkt-ID
    """
    # Extrahiere strukturierte Informationen
    series_code, product_type, language = extract_product_info(title)
    
    # Erstelle eine strukturierte ID
    product_id = f"{base_id}_{series_code}_{product_type}_{language}"
    
    # F√ºge zus√§tzliche Details f√ºr spezielle Produkte hinzu
    if "premium" in title.lower():
        product_id += "_premium"
    if "elite" in title.lower():
        product_id += "_elite"
    if "top" in title.lower() and "trainer" in title.lower():
        product_id += "_top"
    
    return product_id

def fetch_product_details(product_url):
    """
    Ruft detaillierte Produktinformationen direkt von der Produktseite ab
    
    :param product_url: URL der Produktseite
    :return: Dictionary mit Preis und Verf√ºgbarkeitsstatus
    """
    print(f"üîç Rufe Produktdetails von {product_url} ab", flush=True)
    details = {
        "price": "Preis nicht verf√ºgbar",
        "status": "Status unbekannt"
    }
    
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        
        response = requests.get(product_url, headers=headers, timeout=15)
        if response.status_code != 200:
            print(f"‚ö†Ô∏è Fehler beim Abrufen der Produktdetails: Status {response.status_code}", flush=True)
            return details
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        # Preis extrahieren - verschiedene m√∂gliche Selektoren
        price_selectors = [
            ".product__price", 
            ".price", 
            ".product-single__price",
            "[data-product-price]",
            ".product-price",
            ".product-single__price"
        ]
        
        for selector in price_selectors:
            price_elem = soup.select_one(selector)
            if price_elem:
                price_text = price_elem.get_text().strip()
                # Entferne nicht-numerische Zeichen au√üer Punkt und Komma
                price_clean = re.sub(r'[^\d,.]', '', price_text)
                if price_clean:
                    details["price"] = price_clean + "‚Ç¨"
                    print(f"‚úÖ Preis gefunden: {details['price']}", flush=True)
                    break
        
        # Verf√ºgbarkeitsstatus extrahieren
        # Pr√ºfe auf "Ausverkauft"-Indikatoren
        sold_out_indicators = ["ausverkauft", "sold out", "out of stock", "nicht verf√ºgbar", "not available"]
        page_text = soup.get_text().lower()
        
        # Suche nach Verf√ºgbarkeitsindikator im Text
        availability_selectors = [
            ".product-form__inventory", 
            ".product__availability",
            ".stock-status",
            "[data-stock-status]",
            ".inventoryMessage"
        ]
        
        availability_text = ""
        for selector in availability_selectors:
            availability_elem = soup.select_one(selector)
            if availability_elem:
                availability_text = availability_elem.get_text().lower().strip()
                break
        
        # Bestimme Status basierend auf Text
        if any(indicator in page_text for indicator in sold_out_indicators) or any(indicator in availability_text for indicator in sold_out_indicators):
            details["status"] = "‚ùå Ausverkauft"
        elif "vorbestellung" in page_text or "pre-order" in page_text:
            details["status"] = "üîú Vorbestellung"
        elif "add to cart" in page_text or "in den warenkorb" in page_text:
            details["status"] = "‚úÖ Verf√ºgbar"
        
        # Pr√ºfe zus√§tzlich auf Add-to-Cart-Button
        cart_button = soup.select_one("button[name='add'], .add-to-cart, .product-form__cart-submit")
        if cart_button and "disabled" not in cart_button.get("class", []) and "sold-out" not in cart_button.get("class", []):
            details["status"] = "‚úÖ Verf√ºgbar"
        
        print(f"‚úÖ Status gefunden: {details['status']}", flush=True)
        
        # Alternativ: JSON-Daten aus der Seite extrahieren
        # Dies ist eine robustere Methode, da viele Shops Produktdaten als JSON in die Seite einbetten
        script_tags = soup.find_all("script", type="application/ld+json")
        for script in script_tags:
            try:
                import json
                json_data = json.loads(script.string)
                
                # Suche nach Produktdaten im JSON
                if isinstance(json_data, dict) and "offers" in json_data:
                    offers = json_data["offers"]
                    if isinstance(offers, dict):
                        # Preis extrahieren
                        if "price" in offers and offers["price"]:
                            details["price"] = str(offers["price"]) + "‚Ç¨"
                            print(f"‚úÖ Preis aus JSON gefunden: {details['price']}", flush=True)
                        
                        # Verf√ºgbarkeit extrahieren
                        if "availability" in offers:
                            availability = offers["availability"].lower()
                            if "outofstock" in availability:
                                details["status"] = "‚ùå Ausverkauft"
                            elif "preorder" in availability:
                                details["status"] = "üîú Vorbestellung"
                            elif "instock" in availability:
                                details["status"] = "‚úÖ Verf√ºgbar"
                            print(f"‚úÖ Status aus JSON gefunden: {details['status']}", flush=True)
            except Exception as e:
                print(f"‚ö†Ô∏è Fehler beim Parsen der JSON-Daten: {e}", flush=True)
        
    except Exception as e:
        print(f"‚ùå Fehler beim Abrufen der Produktdetails: {e}", flush=True)
    
    return details

def discover_collection_urls():
    """Entdeckt aktuelle Collection-URLs durch Scraping der Hauptseite"""
    from bs4 import BeautifulSoup
    
    print("üîç Suche nach g√ºltigen Collection-URLs auf der Hauptseite", flush=True)
    valid_urls = []
    
    try:
        # Starte mit der Hauptseite
        main_url = "https://tcgviert.com"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        
        response = requests.get(main_url, headers=headers, timeout=15)
        if response.status_code != 200:
            print(f"‚ö†Ô∏è Fehler beim Abrufen der Hauptseite: Status {response.status_code}", flush=True)
            return []
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        # Finde alle Links auf der Seite
        links = soup.find_all("a", href=True)
        
        # Filtern nach Collection-Links
        collection_urls = []
        for link in links:
            href = link["href"]
            if "/collections/" in href and "tcgviert.com" not in href:
                # Vollst√§ndige URL erstellen, wenn n√∂tig
                full_url = f"{main_url}{href}" if href.startswith("/") else href
                collection_urls.append(full_url)
        
        # Duplikate entfernen
        collection_urls = list(set(collection_urls))
        print(f"üîç {len(collection_urls)} m√∂gliche Collection-URLs gefunden", flush=True)
        
        # Pr√ºfe, welche URLs tats√§chlich existieren
        for url in collection_urls:
            try:
                test_response = requests.get(url, headers=headers, timeout=10)
                if test_response.status_code == 200:
                    valid_urls.append(url)
                    print(f"‚úÖ G√ºltige Collection-URL gefunden: {url}", flush=True)
            except Exception:
                pass
        
        # Gib immer die URL f√ºr "alle Produkte" mit zur√ºck
        all_products_url = f"{main_url}/collections/all"
        if all_products_url not in valid_urls:
            valid_urls.append(all_products_url)
            print(f"‚úÖ F√ºge Standard-URL hinzu: {all_products_url}", flush=True)
        
        print(f"üîç Insgesamt {len(valid_urls)} g√ºltige Collection-URLs gefunden", flush=True)
        
        # Beschr√§nke auf eine kleinere Anzahl relevanter URLs, um Duplikate zu vermeiden
        # Priorisiere spezifische URLs, die mit den Suchbegriffen zu tun haben
        priority_urls = []
        for url in valid_urls:
            if any(term in url.lower() for term in ["journey", "together", "sv09", "reise", "kp09", "royal", "blood", "vorbestellungen"]):
                priority_urls.append(url)
        
        # F√ºge die Standard-URLs hinzu
        for url in ["https://tcgviert.com/collections/all", "https://tcgviert.com/collections/vorbestellungen"]:
            if url in valid_urls and url not in priority_urls:
                priority_urls.append(url)
        
        # Wenn wir priorisierte URLs haben, verwende nur diese
        if priority_urls:
            print(f"üîç Verwende {len(priority_urls)} priorisierte URLs: {priority_urls}", flush=True)
            return priority_urls
        
        return valid_urls
        
    except Exception as e:
        print(f"‚ùå Fehler bei der Collection-URL-Entdeckung: {e}", flush=True)
        return ["https://tcgviert.com/collections/all"]  # Fallback zur Alle-Produkte-Seite

def scrape_tcgviert_json(keywords_map, seen):
    """JSON-Scraper f√ºr tcgviert.com"""
    new_matches = []
    
    try:
        # Versuche zuerst den JSON-Endpunkt
        response = requests.get("https://tcgviert.com/products.json", timeout=10)
        if response.status_code != 200:
            print("‚ö†Ô∏è API antwortet nicht mit Status 200", flush=True)
            return []
        
        data = response.json()
        if "products" not in data or not data["products"]:
            print("‚ö†Ô∏è Keine Produkte im JSON gefunden", flush=True)
            return []
        
        products = data["products"]
        print(f"üîç {len(products)} Produkte zum Pr√ºfen gefunden (JSON)", flush=True)
        
        # Debug-Ausgabe f√ºr alle Produkte mit bestimmten Keywords
        print("üîç Alle Produkte mit Journey Together oder Reisegef√§hrten im Titel:", flush=True)
        journey_products = []
        for product in products:
            title = product["title"]
            if "journey together" in title.lower() or "reisegef√§hrten" in title.lower():
                print(f"  - {title}", flush=True)
                journey_products.append(product)
        
        print(f"üîç {len(journey_products)} Produkte mit gesuchten Keywords gefunden", flush=True)
        
        for product in products:
            title = product["title"]
            handle = product["handle"]
            
            print(f"üîç Pr√ºfe Produkt: '{title}'", flush=True)
            
            # Erstelle eine eindeutige ID basierend auf den Produktinformationen
            product_id = create_product_id(title)
            
            # Pr√ºfe jeden Suchbegriff gegen den Produkttitel
            matched_term = None
            for search_term, tokens in keywords_map.items():
                match_result = is_keyword_in_text(tokens, title)
                print(f"  - Vergleiche mit '{search_term}' (Tokens: {tokens}): {match_result}", flush=True)
                
                if match_result:
                    matched_term = search_term
                    break
            
            if matched_term and product_id not in seen:
                # Produkt wurde noch nicht gemeldet
                url = f"https://tcgviert.com/products/{handle}"
                
                # Preis aus der ersten Variante extrahieren, falls vorhanden
                price = "Preis unbekannt"
                if product.get("variants") and len(product["variants"]) > 0:
                    price = f"{product['variants'][0].get('price', 'N/A')}‚Ç¨"
                
                # Status pr√ºfen (verf√ºgbar/ausverkauft)
                available = False
                for variant in product.get("variants", []):
                    if variant.get("available", False):
                        available = True
                        break
                
                status = "‚úÖ Verf√ºgbar" if available else "‚ùå Ausverkauft"
                
                # Nachricht zusammenstellen
                msg = (
                    f"üéØ *{title}*\n"
                    f"üí∂ {price}\n"
                    f"üìä {status}\n"
                    f"üîé Treffer f√ºr: '{matched_term}'\n"
                    f"üîó [Zum Produkt]({url})"
                )
                
                # Telegram-Nachricht senden
                if send_telegram_message(msg):
                    seen.add(product_id)
                    new_matches.append(product_id)
                    print(f"‚úÖ Neuer Treffer gefunden: {title}", flush=True)
        
    except Exception as e:
        print(f"‚ùå Fehler beim TCGViert JSON-Scraping: {e}", flush=True)
    
    return new_matches

def scrape_tcgviert_html(urls, keywords_map, seen):
    """HTML-Scraper f√ºr tcgviert.com"""
    print("üîÑ Starte HTML-Scraping f√ºr tcgviert.com", flush=True)
    new_matches = []
    
    from bs4 import BeautifulSoup
    
    for url in urls:
        try:
            print(f"üîç Durchsuche {url}", flush=True)
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }
            response = requests.get(url, headers=headers, timeout=15)
            if response.status_code != 200:
                print(f"‚ö†Ô∏è Fehler beim Abrufen von {url}: Status {response.status_code}", flush=True)
                continue
            
            soup = BeautifulSoup(response.text, "html.parser")
            
            # Versuche verschiedene CSS-Selektoren f√ºr Produktkarten
            product_selectors = [
                ".product-card", 
                ".grid__item", 
                ".grid-product",
                "[data-product-card]",
                ".product-item"
            ]
            
            products = []
            for selector in product_selectors:
                products = soup.select(selector)
                if products:
                    print(f"üîç {len(products)} Produkte mit Selektor '{selector}' gefunden", flush=True)
                    break
            
            if not products:
                print(f"‚ö†Ô∏è Keine Produktkarten auf {url} gefunden. Versuche alle Links...", flush=True)
                # Fallback: Suche alle Links und analysiere Text
                all_links = soup.find_all("a", href=True)
                for link in all_links:
                    href = link.get("href", "")
                    text = link.get_text().strip()
                    
                    if not text or "products/" not in href:
                        continue
                    
                    # Erstelle eine eindeutige ID basierend auf den Produktinformationen
                    product_id = create_product_id(text)
                    
                    matched_term = None
                    for search_term, tokens in keywords_map.items():
                        if is_keyword_in_text(tokens, text):
                            matched_term = search_term
                            break
                    
                    if matched_term and product_id not in seen:
                        # Vollst√§ndige URL erstellen
                        product_url = f"https://tcgviert.com{href}" if href.startswith("/") else href
                        
                        # NEU: Rufe detaillierte Produktinformationen ab
                        product_details = fetch_product_details(product_url)
                        
                        msg = (
                            f"üéØ *{text}*\n"
                            f"üí∂ {product_details['price']}\n"
                            f"üìä {product_details['status']}\n"
                            f"üîé Treffer f√ºr: '{matched_term}'\n"
                            f"üîó [Zum Produkt]({product_url})"
                        )
                        
                        if send_telegram_message(msg):
                            seen.add(product_id)
                            new_matches.append(product_id)
                            print(f"‚úÖ Neuer Treffer gefunden (HTML-Link): {text}", flush=True)
                continue
            
            # Debug-Ausgabe f√ºr Journey Together oder Reisegef√§hrten Produkte
            journey_products = []
            for product in products:
                # Verschiedene Selektoren f√ºr Produkttitel versuchen
                title_selectors = [
                    ".product-card__title", 
                    ".grid-product__title", 
                    ".product-title", 
                    ".product-item__title", 
                    "h3", "h2"
                ]
                
                title_elem = None
                for selector in title_selectors:
                    title_elem = product.select_one(selector)
                    if title_elem:
                        break
                
                if not title_elem:
                    continue
                
                title = title_elem.text.strip()
                
                if "journey together" in title.lower() or "reisegef√§hrten" in title.lower():
                    print(f"  - HTML-Produkt: {title}", flush=True)
                    journey_products.append(title)
            
            print(f"üîç {len(journey_products)} HTML-Produkte mit gesuchten Keywords gefunden", flush=True)
            
            for product in products:
                # Extrahiere Titel mit verschiedenen Selektoren
                title_selectors = [
                    ".product-card__title", 
                    ".grid-product__title", 
                    ".product-title", 
                    ".product-item__title", 
                    "h3", "h2"
                ]
                
                title_elem = None
                for selector in title_selectors:
                    title_elem = product.select_one(selector)
                    if title_elem:
                        break
                
                if not title_elem:
                    continue
                
                title = title_elem.text.strip()
                print(f"üîç Pr√ºfe HTML-Produkt: '{title}'", flush=True)
                
                # Link extrahieren
                link_elem = product.find("a", href=True)
                if not link_elem:
                    continue
                
                relative_url = link_elem.get("href", "")
                product_url = f"https://tcgviert.com{relative_url}" if relative_url.startswith("/") else relative_url
                
                # Preis extrahieren
                price_selectors = [
                    ".product-card__price", 
                    ".grid-product__price", 
                    ".product-price", 
                    ".price", 
                    "[data-price]"
                ]
                
                price_elem = None
                for selector in price_selectors:
                    price_elem = product.select_one(selector)
                    if price_elem:
                        break
                
                initial_price = price_elem.text.strip() if price_elem else "Preis nicht verf√ºgbar"
                
                # Erstelle eine eindeutige ID basierend auf den Produktinformationen
                product_id = create_product_id(title)
                
                # Pr√ºfe jeden Suchbegriff gegen den Produkttitel
                matched_term = None
                for search_term, tokens in keywords_map.items():
                    match_result = is_keyword_in_text(tokens, title)
                    print(f"  - Vergleiche mit '{search_term}' (Tokens: {tokens}): {match_result}", flush=True)
                    
                    if match_result:
                        matched_term = search_term
                        break
                
                if matched_term and product_id not in seen:
                    # Status initial bestimmen
                    initial_status = "Unbekannt"
                    if "ausverkauft" in product.text.lower() or "sold out" in product.text.lower():
                        initial_status = "‚ùå Ausverkauft"
                    elif "vorbestellung" in product.text.lower() or "pre-order" in product.text.lower():
                        initial_status = "üîú Vorbestellung"
                    else:
                        initial_status = "‚úÖ Verf√ºgbar"
                    
                    # NEU: Wenn Preis oder Status unbekannt/nicht verf√ºgbar sind, rufe Produktdetails ab
                    if initial_price == "Preis nicht verf√ºgbar" or initial_status == "Unbekannt" or initial_status == "Status unbekannt":
                        print(f"üîç Fehlende Informationen - rufe Produktseite f√ºr Details ab: {product_url}", flush=True)
                        product_details = fetch_product_details(product_url)
                        price = product_details["price"]
                        status = product_details["status"]
                    else:
                        price = initial_price
                        status = initial_status
                    
                    msg = (
                        f"üéØ *{title}*\n"
                        f"üí∂ {price}\n"
                        f"üìä {status}\n"
                        f"üîé Treffer f√ºr: '{matched_term}'\n"
                        f"üîó [Zum Produkt]({product_url})"
                    )
                    
                    if send_telegram_message(msg):
                        seen.add(product_id)
                        new_matches.append(product_id)
                        print(f"‚úÖ Neuer Treffer gefunden (HTML): {title}", flush=True)
            
        except Exception as e:
            print(f"‚ùå Fehler beim Scrapen von {url}: {e}", flush=True)
    
    return new_matches

# Generische Version f√ºr Anpassung an andere Webseiten
def generic_scrape_product(url, product_title, product_url, price, status, matched_term, seen, new_matches, site_id="generic"):
    """
    Generische Funktion zur Verarbeitung gefundener Produkte f√ºr beliebige Websites
    
    :param url: URL der aktuellen Seite
    :param product_title: Produkttitel
    :param product_url: Produkt-URL 
    :param price: Produktpreis
    :param status: Verf√ºgbarkeitsstatus
    :param matched_term: √úbereinstimmender Suchbegriff
    :param seen: Set mit bereits gesehenen Produkt-IDs
    :param new_matches: Liste der neu gefundenen Produkt-IDs
    :param site_id: ID der Website (f√ºr Produkt-ID-Erstellung)
    :return: None
    """
    # Erstelle eine eindeutige ID basierend auf den Produktinformationen
    product_id = create_product_id(product_title, base_id=site_id)
    
    # NEU: Wenn Preis oder Status unbekannt/nicht verf√ºgbar sind, rufe Produktdetails ab
    if price == "Preis nicht verf√ºgbar" or status == "Status unbekannt" or status == "Unbekannt":
        print(f"üîç Fehlende Informationen - rufe Produktseite f√ºr Details ab: {product_url}", flush=True)
        product_details = fetch_product_details(product_url)
        price = product_details["price"]
        status = product_details["status"]
    
    if product_id not in seen:
        msg = (
            f"üéØ *{product_title}*\n"
            f"üí∂ {price}\n"
            f"üìä {status}\n"
            f"üîé Treffer f√ºr: '{matched_term}'\n"
            f"üîó [Zum Produkt]({product_url})"
        )
        
        if send_telegram_message(msg):
            seen.add(product_id)
            new_matches.append(product_id)
            print(f"‚úÖ Neuer Treffer gefunden ({site_id}): {product_title}", flush=True)